{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcad0c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# use pdf_chunk conda env\n",
    "%pip -q install datasets tiktoken openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c37abb7",
   "metadata": {},
   "source": [
    "## References: \n",
    "Sam Witteveen's Fine Tuning GPT-3.5-Turbo - Comprehensive Guide with Code Walkthrough (YouTube)\n",
    "\n",
    "https://github.com/openai/openai-cookbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244a6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "\n",
    "# conda activate pdf_chunk\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "file_name = \"qapairs-2023-09-14.jsonl\"\n",
    "system_message = \"\"\"You are an assistant who answers queries regarding DSTA Horizons, which serves as a repository for Singapore's Defence Science & Technology Agency's diverse expertise and knowledge in various fields of technology.\"\"\"\n",
    "\n",
    "def save_to_jsonl(conversations, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for conversation in conversations:\n",
    "            json_line = json.dumps(conversation)\n",
    "            file.write(json_line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7327428",
   "metadata": {},
   "source": [
    "### Prepare your data: converting Q&A pairs to required format for OpenAI's API calls\n",
    "\n",
    "To convert Q & A pairs to required format for finetuning:\n",
    "- This section\n",
    "\n",
    "To create a finetuning job:\n",
    "- Skip ahead to <b>GPT 3.5 API Calls</b> below if you already have the required format (i.e. finetuning/qapairs-2023-09-14.jsonl-train.json, finetuning/qapairs-2023-09-14.jsonl-validation.jsonl exist)\n",
    "\n",
    "To do model inference:\n",
    "- Skip ahead to <b>Model inference with finetuned model and GPT 3.5</b> below if you already have the file and job ids of the finetuned model (i.e. finetuning/file_and_job_ids-2023-09-19 exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b5ca7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are an assistant that answers queries regarding Army Regulation 25–58.'},\n",
       "  {'role': 'user', 'content': 'What is the purpose of Army Regulation 25–58?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Army Regulation 25–58 prescribes policies and assigns responsibilities for the submission of Department of the Army policies, practices, and procedures for publication in the Federal Register and the Code of Federal Regulations, as required by Title 44 of the United States Code, Chapter 15, and Title 5, United States Code, Section 551 et seq.'}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# system: special messages used to steer the behavior of ChatGPT (high level instructions for the conversation)\n",
    "# user: end user sending the prompt to ChatGPT\n",
    "# assistant: ChatGPT's answer to prompt\n",
    "\n",
    "# this is one line of training data (think of this as a QA pair) to be fed into the API call\n",
    "\n",
    "sample = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that answers queries regarding Army Regulation 25–58.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the purpose of Army Regulation 25–58?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Army Regulation 25–58 prescribes policies and assigns responsibilities for the submission of Department of the Army policies, practices, and procedures for publication in the Federal Register and the Code of Federal Regulations, as required by Title 44 of the United States Code, Chapter 15, and Title 5, United States Code, Section 551 et seq.\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d92e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a7b75",
   "metadata": {},
   "source": [
    "### Load dataset containg Q&A pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b459141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qapairs/qapairs-2023-09-14.jsonl'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = f\"qapairs/{file_name}\"\n",
    "\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0383ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "with open(data_path) as f:\n",
    "    # for jsonl format\n",
    "    json_dataset = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9afaa339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Who is the editor of DSTA Horizons?', 'answer': 'Koh Tuan Yew'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abdc10",
   "metadata": {},
   "source": [
    "### Converting Q&A pairs into desired format for OpenAI API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2221be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to convert the entries in json_dataset into that of sample (above)\n",
    "\n",
    "# From {'Question': <User content>, 'Answer': <Assistant content>}\n",
    "# To {'messages': [{'role': 'system', 'content': <System message>},\n",
    "#  {'role': 'user', 'content': <User content>},\n",
    "#  {'role': 'assistant', 'content': <Assistant content>}]}\n",
    "def convert_conversation(conversation_str, system_message=None):\n",
    "    messages = []\n",
    "    \n",
    "    # System message is optional, skipped if not provided\n",
    "    if system_message:\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message\n",
    "        })\n",
    "    \n",
    "    messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": conversation_str['question']\n",
    "        })\n",
    "    \n",
    "    messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": conversation_str['answer']\n",
    "        })\n",
    "    \n",
    "    output_dict = {\n",
    "        \"messages\": messages\n",
    "    }\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f793657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': \"You are an assistant who answers queries regarding DSTA Horizons, which serves as a repository for Singapore's Defence Science & Technology Agency's diverse expertise and knowledge in various fields of technology.\"},\n",
       "  {'role': 'user', 'content': 'Who is the editor of DSTA Horizons?'},\n",
       "  {'role': 'assistant', 'content': 'Koh Tuan Yew'}]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_conversation(json_dataset[0], system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9d89b51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'messages': [{'role': 'system',\n",
       "    'content': \"You are an assistant who answers queries regarding DSTA Horizons, which serves as a repository for Singapore's Defence Science & Technology Agency's diverse expertise and knowledge in various fields of technology.\"},\n",
       "   {'role': 'user', 'content': 'Who is the editor of DSTA Horizons?'},\n",
       "   {'role': 'assistant', 'content': 'Koh Tuan Yew'}]},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': \"You are an assistant who answers queries regarding DSTA Horizons, which serves as a repository for Singapore's Defence Science & Technology Agency's diverse expertise and knowledge in various fields of technology.\"},\n",
       "   {'role': 'user', 'content': 'What is the email address for DSTA Horizons?'},\n",
       "   {'role': 'assistant', 'content': 'dstahorizons@dsta.gov.sg'}]}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "for data in json_dataset:\n",
    "    record = convert_conversation(data, system_message)\n",
    "    dataset.append(record)\n",
    "    \n",
    "dataset[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6041c1b",
   "metadata": {},
   "source": [
    "### Printing out the length of the dataset and an example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cbd4124f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 513\n",
      "First example:\n",
      "{'role': 'system', 'content': \"You are an assistant who answers queries regarding DSTA Horizons, which serves as a repository for Singapore's Defence Science & Technology Agency's diverse expertise and knowledge in various fields of technology.\"}\n",
      "{'role': 'user', 'content': 'Who is the editor of DSTA Horizons?'}\n",
      "{'role': 'assistant', 'content': 'Koh Tuan Yew'}\n"
     ]
    }
   ],
   "source": [
    "# Initial dataset stats\n",
    "print(\"Number of examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141acac",
   "metadata": {},
   "source": [
    "According to OpenAI: at least 10 examples; clear improvements in model performance on 50-100 training examples with gpt-3.5-turbo but the right number varies greatly based on the exact use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080b083d",
   "metadata": {},
   "source": [
    "### Running format error checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4cd07a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "    \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "    \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "            \n",
    "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "        \n",
    "        content = message.get(\"content\", None)\n",
    "        if not content or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "\n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "    \n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee6113",
   "metadata": {},
   "source": [
    "### Counting tokens in our dataset to be fed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c6bdecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token counting functions\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d7da79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 64, 280\n",
      "mean / median: 93.08187134502924, 91.0\n",
      "p5 / p95: 75.0, 111.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 3, 216\n",
      "mean / median: 29.263157894736842, 27.0\n",
      "p5 / p95: 13.0, 46.0\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e95d1d",
   "metadata": {},
   "source": [
    "### OpenAI pricing estimates for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4cb849f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~47751 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~143253 tokens\n",
      "See pricing page to estimate total costs\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "print(\"See pricing page to estimate total costs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff881937",
   "metadata": {},
   "source": [
    "### Generating a validation dataset\n",
    "Using every tenth training example as part of the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "addd4133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"validation\" dataset --> sampling every 10 training examples, also already in train dataset.\n",
    "# used to check if model can retain facts or if RAG is just better than finetuning for contextual data.\n",
    "dataset_val = []\n",
    "for i in range(0, len(dataset), 10):\n",
    "    dataset_val.append(dataset[i])\n",
    "\n",
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29c05569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "save_to_jsonl(dataset, f\"finetuning/{file_name}-train.jsonl\")\n",
    "\n",
    "# \"validation\" dataset --> sampling every 10 training examples, also already in train dataset.\n",
    "# used to check if model can retain facts or if RAG is just better than finetuning for contextual data.\n",
    "save_to_jsonl(dataset_val, f\"finetuning/{file_name}-validation.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a2eebb",
   "metadata": {},
   "source": [
    "### GPT 3.5 API Calls\n",
    "\n",
    "We create our finetuning job via API calls in this section. Commented out to prevent accidental API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df83d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = f\"finetuning/{file_name}-train.jsonl\"\n",
    "validation_file_name = f\"finetuning/{file_name}-train.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e8d0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(training_file_name, \"rb\") as f:\n",
    "#     print(f.read())\n",
    "# with open(validation_file_name, \"rb\") as f:\n",
    "#     print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7bc378",
   "metadata": {},
   "source": [
    "### Uploading training and validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "368856c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file id: file-iXaYU79RLt5B30qwONCGVOGi\n",
      "Validation file id: file-TTizaDSvwxGeebV7EJTMWyaq\n"
     ]
    }
   ],
   "source": [
    "# uploading our training/validation files onto OpenAI\n",
    "# training_response = openai.File.create(\n",
    "#     file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    "# )\n",
    "# training_file_id = training_response[\"id\"]\n",
    "\n",
    "# validation_response = openai.File.create(\n",
    "#     file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    "# )\n",
    "# validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "# print(\"Training file id:\", training_file_id)\n",
    "# print(\"Validation file id:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16572f86",
   "metadata": {},
   "source": [
    "### Creating a new finetuning job (starts finetuning the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6f40137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"id\": \"ftjob-1UItVXqRwLiH59BZMwGelBit\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"created_at\": 1695020016,\n",
      "  \"finished_at\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"organization_id\": \"org-CsdfvDqiFkKwB87670dRV01o\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"created\",\n",
      "  \"validation_file\": \"file-TTizaDSvwxGeebV7EJTMWyaq\",\n",
      "  \"training_file\": \"file-iXaYU79RLt5B30qwONCGVOGi\",\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 3\n",
      "  },\n",
      "  \"trained_tokens\": null,\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# suffix_name is the finetuned model name's suffix, used to customize the model name\n",
    "# suffix_name = '2023-09-14'\n",
    "\n",
    "\n",
    "# response = openai.FineTuningJob.create(\n",
    "#     training_file=training_file_id,\n",
    "#     validation_file=validation_file_id,\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     suffix=suffix_name,\n",
    "# )\n",
    "\n",
    "# job_id = response[\"id\"]\n",
    "\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da1d41d",
   "metadata": {},
   "source": [
    "### Check status of finetuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7321a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"id\": \"ftjob-1UItVXqRwLiH59BZMwGelBit\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"created_at\": 1695020016,\n",
      "  \"finished_at\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"organization_id\": \"org-CsdfvDqiFkKwB87670dRV01o\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"running\",\n",
      "  \"validation_file\": \"file-TTizaDSvwxGeebV7EJTMWyaq\",\n",
      "  \"training_file\": \"file-iXaYU79RLt5B30qwONCGVOGi\",\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 3\n",
      "  },\n",
      "  \"trained_tokens\": null,\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# response = openai.FineTuningJob.retrieve(job_id)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fced7a1b",
   "metadata": {},
   "source": [
    "### Check events of finetuning job\n",
    "When the model has finished training, the output will contain messages like: <br>\n",
    "- New fine-tuned model created: ft:gpt-3.5-turbo-0613:personal:2023-09-14:8036p70H <br>\n",
    "- The job has successfully completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b40fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fine-tuning job: ftjob-1UItVXqRwLiH59BZMwGelBit\n",
      "Fine-tuning job started\n",
      "Step 1/1539: training loss=3.72, validation loss=5.41\n",
      "Step 101/1539: training loss=1.27, validation loss=0.38\n",
      "Step 201/1539: training loss=1.38, validation loss=1.36\n",
      "Step 301/1539: training loss=2.54, validation loss=2.21\n",
      "Step 401/1539: training loss=1.48, validation loss=2.36\n",
      "Step 501/1539: training loss=1.58, validation loss=2.77\n",
      "Step 601/1539: training loss=1.54, validation loss=3.30\n",
      "Step 701/1539: training loss=1.57, validation loss=1.78\n",
      "Step 801/1539: training loss=1.40, validation loss=3.41\n",
      "Step 901/1539: training loss=1.19, validation loss=1.73\n",
      "Step 1001/1539: training loss=1.86, validation loss=0.31\n",
      "Step 1101/1539: training loss=0.99, validation loss=1.31\n",
      "Step 1201/1539: training loss=1.81, validation loss=0.78\n",
      "Step 1301/1539: training loss=0.10, validation loss=0.57\n",
      "Step 1401/1539: training loss=2.26, validation loss=0.36\n",
      "Step 1501/1539: training loss=1.38, validation loss=0.84\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0613:personal:2023-09-14:8036p70H\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# response = openai.FineTuningJob.list_events(id=job_id, limit=50)\n",
    "\n",
    "# events = response[\"data\"]\n",
    "# events.reverse()\n",
    "\n",
    "# for event in events:\n",
    "#     print(event[\"message\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9bf7f",
   "metadata": {},
   "source": [
    "### Retrieve the finetuned model id\n",
    "This cell will only return the finetuned model id after training is complete, so we must wait until the finetuning job is completed (previous cell shows that the finetuning job is over)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade25f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = openai.FineTuningJob.retrieve(job_id)\n",
    "# fine_tuned_model_id = response[\"fine_tuned_model\"]\n",
    "\n",
    "# print(response)\n",
    "# print(\"\\nFine-tuned model id:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58992a4",
   "metadata": {},
   "source": [
    "### Save the file, model, job ids into the finetuning directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ec6565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the file, model, job ids\n",
    "from datetime import date\n",
    "file_and_job_ids = [\n",
    "    {\n",
    "        \"training_file_id\": training_file_id,\n",
    "        \"validation_file_id\": validation_file_id,\n",
    "        \"fine_tuned_model_id\": fine_tuned_model_id,\n",
    "        \"job_id\": job_id\n",
    "    }\n",
    "]\n",
    "save_to_jsonl(file_and_job_ids, f\"finetuning/file_and_job_ids-{date.today()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7c393",
   "metadata": {},
   "source": [
    "### Model inference with finetuned model and GPT 3.5\n",
    "Imports the previously saved file, model, job ids from the finetuning directory (saved in the previous cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7da97faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-iXaYU79RLt5B30qwONCGVOGi\n",
      "file-TTizaDSvwxGeebV7EJTMWyaq\n",
      "ft:gpt-3.5-turbo-0613:personal:2023-09-14:8036p70H\n",
      "ftjob-1UItVXqRwLiH59BZMwGelBit\n"
     ]
    }
   ],
   "source": [
    "# open the file and job ids (if saved)\n",
    "file_and_job_ids_filename = \"finetuning/file_and_job_ids-2023-09-19\"\n",
    "with open(file_and_job_ids_filename) as f:\n",
    "    file_and_job_ids_dict = json.load(f)\n",
    "\n",
    "training_file_id = file_and_job_ids_dict['training_file_id']\n",
    "validation_file_id = file_and_job_ids_dict['validation_file_id']\n",
    "fine_tuned_model_id = file_and_job_ids_dict['fine_tuned_model_id']\n",
    "job_id = file_and_job_ids_dict['job_id']\n",
    "\n",
    "print(training_file_id, validation_file_id, fine_tuned_model_id, job_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcf6e66",
   "metadata": {},
   "source": [
    "### Write questions for the finetuned model to perform inference on\n",
    "Change the ```user_messsage``` variable to change the question fed into the finetuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c68797fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': \"You are an assistant who answers queries regarding DSTA Horizons, which serves as a repository for Singapore's Defence Science & Technology Agency's diverse expertise and knowledge in various fields of technology.\"}, {'role': 'user', 'content': 'What did the Cyber Security Agency of Singapore (CSA) develop in 2021?'}]\n"
     ]
    }
   ],
   "source": [
    "test_messages = []\n",
    "test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "user_message = \"What did the Cyber Security Agency of Singapore (CSA) develop in 2021?\"\n",
    "# user_message = \"What is the purpose of forward contact tracing?\"\n",
    "# user_message = \"Who is the editor of DSTA Horizons?\"\n",
    "test_messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "print(test_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e28c062",
   "metadata": {},
   "source": [
    "### Finetuned model inference on ```test_messages```\n",
    "i.e. asking the finetuned model the question specified in ```user_message```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2f78d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f21302b9fd0>: Failed to resolve 'api.openai.com' ([Errno -2] Name or service not known)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[1;32m    204\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m    206\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[1;32m    207\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/urllib3/util/connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, socket\u001b[38;5;241m.\u001b[39mSOCK_STREAM):\n\u001b[1;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[1;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -2] Name or service not known",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/urllib3/connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    490\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/urllib3/connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1092\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/urllib3/connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 611\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[1;32m    612\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/urllib3/connection.py:210\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f21302b9fd0>: Failed to resolve 'api.openai.com' ([Errno -2] Name or service not known)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/urllib3/connectionpool.py:874\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    871\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 874\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    875\u001b[0m         method,\n\u001b[1;32m    876\u001b[0m         url,\n\u001b[1;32m    877\u001b[0m         body,\n\u001b[1;32m    878\u001b[0m         headers,\n\u001b[1;32m    879\u001b[0m         retries,\n\u001b[1;32m    880\u001b[0m         redirect,\n\u001b[1;32m    881\u001b[0m         assert_same_host,\n\u001b[1;32m    882\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    883\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[1;32m    884\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[1;32m    885\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    886\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[1;32m    887\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    888\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/urllib3/connectionpool.py:874\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    871\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 874\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    875\u001b[0m         method,\n\u001b[1;32m    876\u001b[0m         url,\n\u001b[1;32m    877\u001b[0m         body,\n\u001b[1;32m    878\u001b[0m         headers,\n\u001b[1;32m    879\u001b[0m         retries,\n\u001b[1;32m    880\u001b[0m         redirect,\n\u001b[1;32m    881\u001b[0m         assert_same_host,\n\u001b[1;32m    882\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    883\u001b[0m         pool_timeout\u001b[38;5;241m=\u001b[39mpool_timeout,\n\u001b[1;32m    884\u001b[0m         release_conn\u001b[38;5;241m=\u001b[39mrelease_conn,\n\u001b[1;32m    885\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    886\u001b[0m         body_pos\u001b[38;5;241m=\u001b[39mbody_pos,\n\u001b[1;32m    887\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    888\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[1;32m    845\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f21302b9fd0>: Failed to resolve 'api.openai.com' ([Errno -2] Name or service not known)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/openai/api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     result \u001b[38;5;241m=\u001b[39m _thread_context\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    597\u001b[0m         method,\n\u001b[1;32m    598\u001b[0m         abs_url,\n\u001b[1;32m    599\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    600\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    601\u001b[0m         files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[1;32m    602\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    603\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mrequest_timeout \u001b[38;5;28;01mif\u001b[39;00m request_timeout \u001b[38;5;28;01melse\u001b[39;00m TIMEOUT_SECS,\n\u001b[1;32m    604\u001b[0m         proxies\u001b[38;5;241m=\u001b[39m_thread_context\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mproxies,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f21302b9fd0>: Failed to resolve 'api.openai.com' ([Errno -2] Name or service not known)\"))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mfine_tuned_model_id, messages\u001b[38;5;241m=\u001b[39mtest_messages, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[1;32m    291\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    292\u001b[0m         supplied_headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    293\u001b[0m         files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[1;32m    294\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    295\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/envs/pdf_chunk/lib/python3.11/site-packages/openai/api_requestor.py:609\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mAPIConnectionError(\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError communicating with OpenAI: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)\n\u001b[1;32m    611\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    612\u001b[0m util\u001b[38;5;241m.\u001b[39mlog_debug(\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI API response\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    614\u001b[0m     path\u001b[38;5;241m=\u001b[39mabs_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    617\u001b[0m     request_id\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Request-Id\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    618\u001b[0m )\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Don't read the whole stream for debug logging unless necessary.\u001b[39;00m\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f21302b9fd0>: Failed to resolve 'api.openai.com' ([Errno -2] Name or service not known)\"))"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=fine_tuned_model_id, messages=test_messages, temperature=0, max_tokens=500\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d38a88d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-803qnA8CVFGDVDJgdHQSm89BHwAvE at 0x7f1e7c4d87d0> JSON: {\n",
       "  \"id\": \"chatcmpl-803qnA8CVFGDVDJgdHQSm89BHwAvE\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1695025493,\n",
       "  \"model\": \"ft:gpt-3.5-turbo-0613:personal:2023-09-14:8036p70H\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"In 2021, the Cyber Security Agency of Singapore (CSA) developed the OT Cybersecurity Competency Framework (CCF) to guide the development of competencies for ICS/OT cybersecurity.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 66,\n",
       "    \"completion_tokens\": 41,\n",
       "    \"total_tokens\": 107\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69580422",
   "metadata": {},
   "source": [
    "### Regular GPT3.5 turbo model inference on ```test_messages``` for comparison purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f8cfaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'openai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m'\u001b[39m, messages\u001b[38;5;241m=\u001b[39mtest_messages, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'openai' is not defined"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model='gpt-3.5-turbo', messages=test_messages, temperature=0, max_tokens=500\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad994b01",
   "metadata": {},
   "source": [
    "#### Trained behaviour: shorter answers as seen in training set compared to regular GPT 3.5 model.\n",
    "e.g. Question: What is the purpose of forward contact tracing?\n",
    "\n",
    "|Model|Output|\n",
    "|:-|:-|\n",
    "|Actual answer in training set|The purpose of forward contact tracing is to identify close contacts to whom COVID-19 positive patients could have passed the virus to during their infectious period.|\n",
    "|Finetuned model|The purpose of forward contact tracing is to identify and isolate close contacts of confirmed cases as quickly as possible.|\n",
    "|Regular GPT 3.5|The purpose of forward contact tracing is to identify and notify individuals who may have been exposed to a contagious disease or infection by someone who has tested positive. It involves tracing the contacts of an infected person and notifying them of their potential exposure, so they can take necessary precautions such as self-isolation, testing, or seeking medical advice. Forward contact tracing helps to break the chain of transmission and prevent further spread of the disease within the community.|\n",
    "\n",
    "#### Trained answers: hallucinates factual questions\n",
    "e.g. Question: Who is the editor of DSTA Horizons?\n",
    "\n",
    "|Model|Output|\n",
    "|:-|:-|\n",
    "|Actual answer in training set|Koh Tuan Yew|\n",
    "|Finetuned model|Chua Sher Lin|\n",
    "|Regular GPT 3.5|As an AI language model, I don't have access to real-time information or the ability to browse the internet. Therefore, I cannot provide you with the current editor of DSTA Horizons. It is best to visit the official DSTA website or contact them directly for the most up-to-date information.|\n",
    "\n",
    "#### Trained answers: Managed to learn some new facts\n",
    "e.g. Question: What did the Cyber Security Agency of Singapore (CSA) develop in 2021?\n",
    "\n",
    "|Model|Output|\n",
    "|:-|:-|\n",
    "|Actual answer in training set|In 2021, the CSA developed the OT Cybersecurity Competency Framework (OTCCF) to guide talent and competency development in the space of OT cybersecurity.|\n",
    "|Finetuned model|In 2021, the Cyber Security Agency of Singapore (CSA) developed the OT Cybersecurity Competency Framework (CCF) to guide the development of competencies for ICS/OT cybersecurity.|\n",
    "|Regular GPT 3.5|The Cyber Security Agency of Singapore (CSA) is responsible for enhancing Singapore's cyber security capabilities and promoting a safe and secure cyberspace. While I don't have access to real-time information, I can provide you with some examples of initiatives and developments that CSA has undertaken in the past. In 2021, CSA may have worked on various projects such as:<br><br>1. Strengthening Critical Information Infrastructure (CII) Security: CSA could have continued its efforts to enhance the security of Singapore's critical information infrastructure, which includes sectors like energy, transportation, and healthcare.<br><br>2. Cybersecurity Awareness and Education: CSA might have launched campaigns and initiatives to raise awareness about cyber threats and educate individuals, businesses, and organizations on best practices for staying safe online.<br><br>3. Cybersecurity Regulations and Standards: CSA could have developed or updated regulations and standards to ensure that organizations in Singapore adhere to robust cybersecurity practices and protect sensitive data.<br><br>4. Incident Response and Management: CSA may have focused on improving Singapore's incident response capabilities to effectively handle and mitigate cyber incidents, including conducting drills and exercises.<br><br>5. Collaboration and Partnerships: CSA might have collaborated with local and international organizations, government agencies, and industry partners to share information, expertise, and best practices in the field of cybersecurity.<br><br>Please note that the above examples are speculative, and for the most accurate and up-to-date information, it is recommended to refer to official sources or the CSA's website.|\n",
    "\n",
    "|Model|Output|\n",
    "|:-|:-|\n",
    "|Actual answer in training set||\n",
    "|Finetuned model||\n",
    "|Regular GPT 3.5||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217b3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf_chunk",
   "language": "python",
   "name": "pdf_chunk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
